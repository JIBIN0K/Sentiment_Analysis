Best performance for traditional models is 0.61 (SVM), performance for transformer(BERT) is 0.74. BERT outperforms traditional models for this dataset.
From the same example test resulst, Bert gave more accurate sentiment anlysis compared to TF-IDF + classical ML models.
Tweaks that helped improve model accracy:
Enahncing text preprocess function, including emoji/emoticons (this helps transformer accuracy boosting)
Bayesian Optimization not really helpful in this case study.
